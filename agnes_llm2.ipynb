{
 "cells": [
  {
   "cell_type": "code",
   "id": "70ad0e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:11:33.800171Z",
     "start_time": "2025-07-08T11:11:30.156020Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:07:03.139733Z",
     "start_time": "2025-07-08T13:06:40.085562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"baidu/ERNIE-4.5-0.3B-PT\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "# decode the generated ids\n",
    "generate_text = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "print(\"generate_text:\", generate_text)\n"
   ],
   "id": "4d70c24942f99a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e867e35f94e147c8aa3a42cfa8f371b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adf4c0b4ab5c4882b8844efedd0b9143"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0995e643c60486caf1ebc99634ea4c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b48d3b7600f427aae7ca1fa835d12e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "configuration_ernie4_5.py: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6a2b86e41d74fbba0eb7587743dbf3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/baidu/ERNIE-4.5-0.3B-PT:\n",
      "- configuration_ernie4_5.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modeling_ernie4_5.py: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3196cdbaf99945aeb9376a5daab404eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/baidu/ERNIE-4.5-0.3B-PT:\n",
      "- modeling_ernie4_5.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/722M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d4128eaaf414af888eb994454a204c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/226 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "076bb90bbac24d55a073738e4ff06829"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_text: **Short Introduction:** Large language models (LLMs) are artificial intelligence systems that simulate human-like intelligence through natural language processing and computational reasoning. They enable users to engage in complex conversations, generate text, solve puzzles, and perform tasks requiring high-level reasoning, such as writing essays, creating articles, or even understanding human language. Unlike traditional chatbots, LLMs operate independently, processing data from large datasets to provide context-aware responses. Their development has revolutionized communication, productivity, and creativity across industries like healthcare, finance, and education.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "bb414a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:11:37.132672Z",
     "start_time": "2025-07-08T11:11:35.828435Z"
    }
   },
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "63c4b091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:11:43.675174Z",
     "start_time": "2025-07-08T11:11:41.394981Z"
    }
   },
   "source": [
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello, I\\'m a language model, and this is why I love language models. I can think of no language more exciting than a language model. It\\'s the only way of thinking about the world we\\'re living in right now.\\n\\nNow, I have a lot of work to do.\\n\\nI\\'ve had a lot of good conversations with people like you about the importance of languages, and they\\'ve been very supportive. But I want to share with you a great deal of what I think of as a language model.\\n\\nSo let\\'s start with the simplest, most basic, and most basic language model. I use the term \"language model\" because the way I think of language models is that they\\'re the way human beings think about the world. They\\'re not built on any particular set of rules but they\\'re built on a certain set of rules. We can talk about any language model, because they\\'re built on that set of rules. They\\'re built on a certain kind of rules. We can talk about any language model, because they\\'re built on that set of rules.\\n\\nSo I think that the way that a language model is built is very similar to the way a human being is built on a set of rules. A human being has an understanding of the world, and'},\n",
       " {'generated_text': 'Hello, I\\'m a language model, I\\'m not a model of what is possible or what is realistic. But I\\'m not a model of what you can do or can\\'t do. I\\'m a model of what a writer can do. Let me show you.\\n\\nLet\\'s say you\\'re writing a story that\\'s about a group of people. They\\'re all in a bar, and one of them is a girl. You\\'re writing a story about a girl who\\'s been in a bar for 15 years and all of a sudden she\\'s walking down the street.\\n\\nAnd you pick up your phone. You ask the guy in front of her what she\\'s doing. He says, \"I\\'m going to drive her home.\" You say, \"This person is going to drive her home.\" And you\\'re like, \"Well, she doesn\\'t understand why I\\'m driving her home.\"\\n\\nYou\\'re like, \"What about my wife?\" And he says, \"This person is going to drive her home. This person is going to drive her home.\" And you say, \"Well, she doesn\\'t understand why I\\'m driving her home.\"\\n\\nAnd you think about that. And you\\'re like, \"What about my wife?\" And he says, \"This person is going to'},\n",
       " {'generated_text': \"Hello, I'm a language model, not a language model.\\n\\nYou know, if you're working in a language like C or Python, you can use a language model, but it's not a language model.\\n\\nYou can just write a language model if you want.\\n\\nLet's take a look at some examples.\\n\\nYou can have your language model as a syntax tree.\\n\\nJust like a language tree, a syntax tree uses a syntax tree as a structure.\\n\\nThat's right. That's what you're going to do. You're going to create a syntax tree that will have a syntax tree as a structure.\\n\\nYou can use the syntax tree as a syntax tree and then you can use it to represent your code in a way that's more readable and more compact.\\n\\nAnd that's what we're going to do.\\n\\nBut the thing is, we're going to need to define a syntax tree for your code.\\n\\nIf you're going to be using a language model in a language, you're going to have to define your syntax tree in some way that you can easily write and use.\\n\\nSo if you're writing a language model in a language like C, that means that your syntax tree is going to be created\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, and I don\\'t want to be a human being.\"\\n\\n\"I can\\'t speak my own language,\" said the other.\\n\\n\"Are you sure you\\'re speaking the correct language?\" asked the other. \"I don\\'t know!\"\\n\\n\"You\\'re a human being,\" said the other. \"If I didn\\'t speak, you\\'d never know how to speak.\"\\n\\n\"Do you know how to speak?\" asked the other.\\n\\n\"You can hear me?\"\\n\\n\"You can\\'t hear me,\" said the other.\\n\\n\"What does that mean?\" asked the other.\\n\\n\"I just can\\'t talk like that,\" said the other.\\n\\n\"What?\" asked the other.\\n\\n\"I just can\\'t stand it,\" said the other.\\n\\n\"I have a friend that is a language model,\" said the other.\\n\\n\"I have a friend that is a human being,\" said the other. \"I don\\'t know what he\\'s talking about.\"\\n\\n\"I\\'m not a human being,\" said the other.\\n\\n\"I\\'m not a human being,\" said the other.\\n\\n\"You\\'re not a human being,\" said the other.\\n\\n\"I\\'m not a'},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'm the one who created the first real-time, real-time, real-time, real-time, real-time, real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time, real-time-real-time\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "24d36d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:11:47.457583Z",
     "start_time": "2025-07-08T11:11:47.217489Z"
    }
   },
   "source": [
    "dreambank = pd.read_csv('dreambank.csv')\n",
    "dreambank.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     id                      name number       time     date gender age  \\\n",
       "0  alta  Alta: a detailed dreamer      1  1985-1997     1957      F   A   \n",
       "1  alta  Alta: a detailed dreamer      2  1985-1997  8/11/67      F   A   \n",
       "2  alta  Alta: a detailed dreamer      3  1985-1997   8/1/85      F   A   \n",
       "3  alta  Alta: a detailed dreamer      4  1985-1997    1985?      F   A   \n",
       "4  alta  Alta: a detailed dreamer      5  1985-1997    1985?      F   A   \n",
       "\n",
       "                                              report  \\\n",
       "0  The one at the Meads's house, where it's bigge...   \n",
       "1  I'm at a family reunion in a large fine house ...   \n",
       "2  I watch a plane fly past and shortly realize i...   \n",
       "3  Me pulling the green leaves and berries off so...   \n",
       "4  I'm in a room that reminds me of (but definite...   \n",
       "\n",
       "                            character        emotion  \n",
       "0              1MSA, 1FSA, 1FKA, 2ISA            NaN  \n",
       "1                          2MSA, 2JSA            NaN  \n",
       "2        2ISA, 1FSA, 2ISA, 1MKA, 1MKA            NaN  \n",
       "3  1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI            NaN  \n",
       "4        1MKA, 2IOA, 1MKA, 2JSA, 1MSA  CO D, AN 1MKA  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>report</th>\n",
       "      <th>character</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1957</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>The one at the Meads's house, where it's bigge...</td>\n",
       "      <td>1MSA, 1FSA, 1FKA, 2ISA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>2</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/11/67</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm at a family reunion in a large fine house ...</td>\n",
       "      <td>2MSA, 2JSA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>3</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/1/85</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I watch a plane fly past and shortly realize i...</td>\n",
       "      <td>2ISA, 1FSA, 2ISA, 1MKA, 1MKA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>4</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>Me pulling the green leaves and berries off so...</td>\n",
       "      <td>1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>5</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm in a room that reminds me of (but definite...</td>\n",
       "      <td>1MKA, 2IOA, 1MKA, 2JSA, 1MSA</td>\n",
       "      <td>CO D, AN 1MKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "628a392a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:11:55.729610Z",
     "start_time": "2025-07-08T11:11:55.717211Z"
    }
   },
   "source": [
    "name_dream = dreambank['name'].unique()\n",
    "name_dream"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alta: a detailed dreamer', 'Angie: age 18 & 20',\n",
       "       'Arlie: a middle-aged woman', 'Barb Sanders', 'Barb Sanders #2',\n",
       "       'Bay Area girls: Grades 4-6', 'Bay Area girls: Grades 7-9',\n",
       "       'Bea 1: a high school student', 'Bea 2: a college student',\n",
       "       'Blind dreamers (F)', 'Blind dreamers (M)',\n",
       "       'Robert Bosnak: A dream analyst', 'Chris: a transvestite',\n",
       "       'Chuck: a physical scientist', 'College students, 1997-1998 (F)',\n",
       "       'College students, 1997-1998 (M)',\n",
       "       'Dahlia: concerns with appearance', 'David: teenage dreams',\n",
       "       'Dorothea: 53 years of dreams', 'Ed: dreams of his late wife',\n",
       "       'Edna: a blind woman', 'Elizabeth: a woman in her 40s',\n",
       "       'Emma: 48 years of dreams', \"Emma's Husband\",\n",
       "       'Esther: an adolescent girl', 'College women, late 1940s',\n",
       "       'Izzy (ALL, including non-consecutive)',\n",
       "       'Jasmine (ALL, including non-consecutive)',\n",
       "       'Jeff: a lucid dreamer', 'Joan: a lesbian', 'Kenneth',\n",
       "       'Lawrence, a young man', 'Madeline 1: High School',\n",
       "       'Madeline 2: College Dorms', 'Madeline 3: Off-Campus',\n",
       "       'Madeline 4: After College', 'Mack: A poor recaller',\n",
       "       'Mark: a young boy', 'Melissa: a young girl', 'Merri: an artist',\n",
       "       'Miami Home-Lab: Home', 'Miami Home-Lab: Lab',\n",
       "       \"Melora (Melvin's wife)\", \"Melvin (Melora's husband)\",\n",
       "       'Nancy: Caring & headstrong', 'The Natural Scientist',\n",
       "       'Norman: a child molester', 'Hall/VdC Norms: Female',\n",
       "       'Hall/VdC Norms: Male', 'Pegasus: a factory worker',\n",
       "       'Peruvian men', 'Peruvian women', 'Phil 1: teens',\n",
       "       'Phil 2: late 20s', 'Phil 3: retirement', 'The Physiologist',\n",
       "       'Pregnancy & Abortion', 'Ringo: from the 1960s',\n",
       "       'Sally: a forester', 'Samantha: in her 20s', 'Seventh grade girls',\n",
       "       'Midwest teenagers (F)', 'Midwest teenagers (M)',\n",
       "       'West Coast teenage girls', 'Toby: A friendly party animal',\n",
       "       'Tom: An outgoing man', 'UCSC women, 1996', 'Van: a video gamer',\n",
       "       'Vickie: a 10-year-old girl', 'Vietnam Vet: 1970-2008 war dreams',\n",
       "       'Vietnam Vet: 2015 dreams', 'Vietnam Vet: 2016-17 dreams'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c6c336e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:06.744930Z",
     "start_time": "2025-07-08T11:12:06.736793Z"
    }
   },
   "source": [
    "len(dreambank)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27952"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921260c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "48b7cb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:13.720237Z",
     "start_time": "2025-07-08T11:12:13.701524Z"
    }
   },
   "source": [
    "dream_token = dreambank[['name', 'report']]\n",
    "dream_token.tail(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              name  \\\n",
       "27942  Vietnam Vet: 2016-17 dreams   \n",
       "27943  Vietnam Vet: 2016-17 dreams   \n",
       "27944  Vietnam Vet: 2016-17 dreams   \n",
       "27945  Vietnam Vet: 2016-17 dreams   \n",
       "27946  Vietnam Vet: 2016-17 dreams   \n",
       "27947  Vietnam Vet: 2016-17 dreams   \n",
       "27948  Vietnam Vet: 2016-17 dreams   \n",
       "27949  Vietnam Vet: 2016-17 dreams   \n",
       "27950  Vietnam Vet: 2016-17 dreams   \n",
       "27951  Vietnam Vet: 2016-17 dreams   \n",
       "\n",
       "                                                  report  \n",
       "27942  With a community of men and several women, I'm...  \n",
       "27943  A man bearing a likeness to Donald Trump calls...  \n",
       "27944  The sparse jungle offers little camouflage. Hi...  \n",
       "27945  On a desolate farm, in a dirt lot, a very dark...  \n",
       "27946  At night, in a foreign land, I go from one res...  \n",
       "27947  In a town like the town I lived in from 2001 t...  \n",
       "27948  At night, as people leave, I'm standing in a f...  \n",
       "27949  I'm in an airplane flying high over the earth,...  \n",
       "27950  As an adult, I'm living at home with brother a...  \n",
       "27951  I'm part of a bombing mission over India. As w...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27942</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>With a community of men and several women, I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27943</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>A man bearing a likeness to Donald Trump calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>The sparse jungle offers little camouflage. Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27945</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>On a desolate farm, in a dirt lot, a very dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27946</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, in a foreign land, I go from one res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27947</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>In a town like the town I lived in from 2001 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27948</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, as people leave, I'm standing in a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27949</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm in an airplane flying high over the earth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27950</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>As an adult, I'm living at home with brother a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm part of a bombing mission over India. As w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8bb6849b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:32.935055Z",
     "start_time": "2025-07-08T11:12:32.481603Z"
    }
   },
   "source": "#dream_token.to_csv('dream_token.csv', index=False, header=True)",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a5370952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:34.020507Z",
     "start_time": "2025-07-08T11:12:34.013809Z"
    }
   },
   "source": [
    "print(dreambank['report'][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one at the Meads's house, where it's bigger inside than out; there's a European village just inside, with a cobblestone street and a Pied-Piper sort of man with curly hair, he can do things like juggle - I go up the back stairs [there aren't any in the real house] and then down the other side [since there's a second set, immediately] then down a short empty hallway that turns a corner, where I find a tiny room...a young woman with shoulder-length blonde hair in a pageboy is there, cooking at a stove that almost fills the room...she's nice to me. Now outside, I'm waiting for my aunt to pick me up - she arrives in a little round convertible and we go for a drive, not very far - we cross a little bridge over a creek, then double back and she drops me off at the house again. Inside (?) I sit with a couple of people, playing with a string of blue balloons.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "5e67a835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:56.591643Z",
     "start_time": "2025-07-08T11:12:48.100182Z"
    }
   },
   "source": [
    "emails = pd.read_csv('emails.csv')\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "6aa289ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:12:58.135323Z",
     "start_time": "2025-07-08T11:12:58.128123Z"
    }
   },
   "source": [
    "print(len(emails))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517401\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "9af2c583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:13:15.600152Z",
     "start_time": "2025-07-08T11:13:15.593665Z"
    }
   },
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a37319af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T11:13:42.223446Z",
     "start_time": "2025-07-08T11:13:42.214224Z"
    }
   },
   "source": [
    "# Functions to normalize the data\n",
    "\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'name' not in df.columns or 'report' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'prompt' and 'result' columns.\")\n",
    "\n",
    "    conversations = df.apply(lambda row: f\"User: {row['name']}\\nBot: {row['report']}\", axis=1)\n",
    "    return Dataset.from_dict({\"text\": conversations.tolist()})\n",
    "\n",
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cde4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (check this:)\n",
    "\n",
    "#https://huggingface.co/docs/trl/sft_trainer\n",
    "#https://huggingface.co/docs/datasets/loading\n",
    "#https://medium.com/@prashanth.ramanathan/fine-tuning-a-pre-trained-gpt-2-model-and-performing-inference-a-hands-on-guide-57c097a3b810\n",
    "\n",
    "def get_latest_checkpoint(output_dir):\n",
    "    # Look for checkpoint folders like \"checkpoint-500\", \"checkpoint-1000\", etc.\n",
    "    checkpoints = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    # Sort by number and return latest\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    return checkpoints[-1]\n",
    "    \n",
    "def train_model(csv_path, output_dir, model_name=\"openai-community/gpt2\", epochs=3):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    latest_checkpoint = get_latest_checkpoint(output_dir)\n",
    "    model = GPT2LMHeadModel.from_pretrained(latest_checkpoint if latest_checkpoint else model_name)\n",
    "\n",
    "    dataset = load_csv_dataset(csv_path)\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=2,\n",
    "        num_train_epochs=epochs,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        fp16=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=latest_checkpoint if latest_checkpoint else None)\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e686a2-abf7-411e-bc53-b95126abe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#csv_path = 'dream_token.csv'\n",
    "#output_dir = 'trained_model_v1'\n",
    "#train_model(csv_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee5c37-4b2d-4609-b387-3b609a8209d7",
   "metadata": {},
   "source": [
    "# De aqui en adelante emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5026c17-fd69-451d-8226-f98d8b8d5cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c644016e0b964a4aaec6de61045b5d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/517401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74157/780926547.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='776103' max='776103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [776103/776103 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'file' not in df.columns or 'message' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'prompt' and 'result' columns.\")\n",
    "\n",
    "    conversations = df.apply(lambda row: f\"User: {row['file']}\\nBot: {row['message']}\", axis=1)\n",
    "    return Dataset.from_dict({\"text\": conversations.tolist()})\n",
    "\n",
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "\n",
    "csv_path = 'emails_token.csv'\n",
    "output_dir = 'trained_model_v2'\n",
    "train_model(csv_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fc0f8-034a-4df7-ace5-a624156cfeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
