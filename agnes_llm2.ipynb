{
 "cells": [
  {
   "cell_type": "code",
   "id": "70ad0e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:02:45.346019Z",
     "start_time": "2025-07-08T10:02:40.738628Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "bb414a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:03:12.117691Z",
     "start_time": "2025-07-08T10:03:10.655813Z"
    }
   },
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c4b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, I'm not a philosopher. I'm not a scientist. I'm not a mathematician. I'm not a scientist. I'm not a science writer. I'm not a philosopher. I'm not a mathematician. I'm not a scientist. I'm not a scientist. I'm not a philosopher. I'm not a scientist. I'm not a scientist. I'm not a philosopher. I'm not a philosophy writer. I'm not a philosopher. I'm not a philosophy writer. I'm not a philosopher. I'm not a scientist. I'm not a scientist. I'm not a philosopher. I'm not a science writer. I'm not a scientist. I'm not a scientist. I'm not a philosopher. I'm not a philosopher. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a science writer. I'm not a philosophy writer. I'm not a philosopher. I'm not a philosophy writer. I'm not a philosopher. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosophy writer. I'm not a philosopher.\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I'm a model of language design. I don't want to be the one to write that. I want to be the person who creates the language for the world. That's what I'm doing. I just want to do it, and I don't want to be the person who makes the language for the world.\\n\\nI'm not going to try to have a big language. I'm just going to be the person who writes the language and creates the language.\\n\\nI think it's a bit difficult to define, and I think that is why there are so many people who think that I'm not a language model. Some people just have no idea of what it is, and that's fine. I think it's a bit difficult to describe. But there are a lot of people who think that I'm a language model.\\n\\nWe have so many languages. I think that there are a lot of languages that are languages. I think that there are languages that are languages that have languages. I think there are languages that are languages that are languages that have languages.\\n\\nI am a language model. I'm a language design. I'm a language. I'm a model. I'm a model of language design.\\n\\nI'm\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I'm thinking of a language that's supposed to be as simple as possible to learn, as simple as possible to write. I think of it as a model of how the world can be created, how it can be written. I think of it as an idea of how the world works, how it can be lived, how it can be lived, how it can be lived. And I think of it as a model of how the mind gets to work. I think of it as an idea of how the mind gets to see. I think of it as a model of how the mind gets to go. And I think of it as a model of how the mind gets to be.\\n\\nAnd I think of it as a model of how the mind can be taught. I think of it as a model of how the mind can be taught to understand. I think of it as a model of how the mind can be taught to act. I think of it as a model of how the mind can be taught to think.\\n\\nAnd I think of it as a model of how the mind can be taught to act and, for me, a model of how the mind can be taught to think. And I think of it as a model of how the mind\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, and I\\'m not even really a programmer. But I\\'ve probably been around a lot of languages, and I\\'ve worked on a lot of things. I can understand C, I can understand Java. I\\'ve worked on a lot of things, and I\\'m kind of a software engineer. But I\\'ve never really had a career in the industry. But I\\'ve had a lot of friends in the industry, and a lot of people in the industry have worked at Google, and they\\'re like, \"Wow, this is amazing!\"\\n\\nMy first job, I called up Google, and I read some of their blog posts and they said, \"Oh man, this is amazing.\" And I just looked at Google, and I said, \"That\\'s amazing!\" And they said, \"You know, I want to get you on the team.\" And I was like, \"Oh, I\\'ll do that!\"\\n\\nAnd they say, \"If you\\'re going to do this, we\\'ll see you on the team.\"\\n\\nSo I just worked on the team. I worked on the team until I got fired. So I was just a little stuck in the code. And then I got lucky. And I came to a place where I knew I can write'},\n",
       " {'generated_text': 'Hello, I\\'m a language model, I\\'m talking about a language model, and this is something that I\\'m always trying to talk about. I don\\'t want to use the word \"language model,\" I\\'m a language model.\\n\\nBut I\\'ve been able to talk about this, and I want to talk about our culture, my society. I want to talk about the way we live our lives. Well, I want to create a culture, and I want to make it happen.\\n\\nI want to create a culture that is open, that\\'s welcoming, and is inclusive and is inclusive and is inclusive, and that\\'s where we are in the world.\\n\\nAnd so I want to create a culture that is the people that work at the table, the people that get to go out to work, and that\\'s what I\\'m going to be in charge of.\\n\\nI want to be the person that talks to people in the classroom and in the kitchen, and I want to be the person that talks to other students and in the community. I want to be the role model, that\\'s what I\\'m gonna be.\\n\\nAnd I want to be the person that tells us what we need to do. I want to be the person that talks to people in the classroom and'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d36d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>report</th>\n",
       "      <th>character</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1957</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>The one at the Meads's house, where it's bigge...</td>\n",
       "      <td>1MSA, 1FSA, 1FKA, 2ISA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>2</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/11/67</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm at a family reunion in a large fine house ...</td>\n",
       "      <td>2MSA, 2JSA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>3</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/1/85</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I watch a plane fly past and shortly realize i...</td>\n",
       "      <td>2ISA, 1FSA, 2ISA, 1MKA, 1MKA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>4</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>Me pulling the green leaves and berries off so...</td>\n",
       "      <td>1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>5</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm in a room that reminds me of (but definite...</td>\n",
       "      <td>1MKA, 2IOA, 1MKA, 2JSA, 1MSA</td>\n",
       "      <td>CO D, AN 1MKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      name number       time     date gender age  \\\n",
       "0  alta  Alta: a detailed dreamer      1  1985-1997     1957      F   A   \n",
       "1  alta  Alta: a detailed dreamer      2  1985-1997  8/11/67      F   A   \n",
       "2  alta  Alta: a detailed dreamer      3  1985-1997   8/1/85      F   A   \n",
       "3  alta  Alta: a detailed dreamer      4  1985-1997    1985?      F   A   \n",
       "4  alta  Alta: a detailed dreamer      5  1985-1997    1985?      F   A   \n",
       "\n",
       "                                              report  \\\n",
       "0  The one at the Meads's house, where it's bigge...   \n",
       "1  I'm at a family reunion in a large fine house ...   \n",
       "2  I watch a plane fly past and shortly realize i...   \n",
       "3  Me pulling the green leaves and berries off so...   \n",
       "4  I'm in a room that reminds me of (but definite...   \n",
       "\n",
       "                            character        emotion  \n",
       "0              1MSA, 1FSA, 1FKA, 2ISA            NaN  \n",
       "1                          2MSA, 2JSA            NaN  \n",
       "2        2ISA, 1FSA, 2ISA, 1MKA, 1MKA            NaN  \n",
       "3  1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI            NaN  \n",
       "4        1MKA, 2IOA, 1MKA, 2JSA, 1MSA  CO D, AN 1MKA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dreambank = pd.read_csv('dreambank.csv')\n",
    "dreambank.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628a392a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alta: a detailed dreamer', 'Angie: age 18 & 20',\n",
       "       'Arlie: a middle-aged woman', 'Barb Sanders', 'Barb Sanders #2',\n",
       "       'Bay Area girls: Grades 4-6', 'Bay Area girls: Grades 7-9',\n",
       "       'Bea 1: a high school student', 'Bea 2: a college student',\n",
       "       'Blind dreamers (F)', 'Blind dreamers (M)',\n",
       "       'Robert Bosnak: A dream analyst', 'Chris: a transvestite',\n",
       "       'Chuck: a physical scientist', 'College students, 1997-1998 (F)',\n",
       "       'College students, 1997-1998 (M)',\n",
       "       'Dahlia: concerns with appearance', 'David: teenage dreams',\n",
       "       'Dorothea: 53 years of dreams', 'Ed: dreams of his late wife',\n",
       "       'Edna: a blind woman', 'Elizabeth: a woman in her 40s',\n",
       "       'Emma: 48 years of dreams', \"Emma's Husband\",\n",
       "       'Esther: an adolescent girl', 'College women, late 1940s',\n",
       "       'Izzy (ALL, including non-consecutive)',\n",
       "       'Jasmine (ALL, including non-consecutive)',\n",
       "       'Jeff: a lucid dreamer', 'Joan: a lesbian', 'Kenneth',\n",
       "       'Lawrence, a young man', 'Madeline 1: High School',\n",
       "       'Madeline 2: College Dorms', 'Madeline 3: Off-Campus',\n",
       "       'Madeline 4: After College', 'Mack: A poor recaller',\n",
       "       'Mark: a young boy', 'Melissa: a young girl', 'Merri: an artist',\n",
       "       'Miami Home-Lab: Home', 'Miami Home-Lab: Lab',\n",
       "       \"Melora (Melvin's wife)\", \"Melvin (Melora's husband)\",\n",
       "       'Nancy: Caring & headstrong', 'The Natural Scientist',\n",
       "       'Norman: a child molester', 'Hall/VdC Norms: Female',\n",
       "       'Hall/VdC Norms: Male', 'Pegasus: a factory worker',\n",
       "       'Peruvian men', 'Peruvian women', 'Phil 1: teens',\n",
       "       'Phil 2: late 20s', 'Phil 3: retirement', 'The Physiologist',\n",
       "       'Pregnancy & Abortion', 'Ringo: from the 1960s',\n",
       "       'Sally: a forester', 'Samantha: in her 20s', 'Seventh grade girls',\n",
       "       'Midwest teenagers (F)', 'Midwest teenagers (M)',\n",
       "       'West Coast teenage girls', 'Toby: A friendly party animal',\n",
       "       'Tom: An outgoing man', 'UCSC women, 1996', 'Van: a video gamer',\n",
       "       'Vickie: a 10-year-old girl', 'Vietnam Vet: 1970-2008 war dreams',\n",
       "       'Vietnam Vet: 2015 dreams', 'Vietnam Vet: 2016-17 dreams'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dream = dreambank['name'].unique()\n",
    "name_dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c336e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dreambank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921260c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b7cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27942</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>With a community of men and several women, I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27943</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>A man bearing a likeness to Donald Trump calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>The sparse jungle offers little camouflage. Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27945</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>On a desolate farm, in a dirt lot, a very dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27946</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, in a foreign land, I go from one res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27947</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>In a town like the town I lived in from 2001 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27948</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, as people leave, I'm standing in a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27949</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm in an airplane flying high over the earth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27950</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>As an adult, I'm living at home with brother a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm part of a bombing mission over India. As w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "27942  Vietnam Vet: 2016-17 dreams   \n",
       "27943  Vietnam Vet: 2016-17 dreams   \n",
       "27944  Vietnam Vet: 2016-17 dreams   \n",
       "27945  Vietnam Vet: 2016-17 dreams   \n",
       "27946  Vietnam Vet: 2016-17 dreams   \n",
       "27947  Vietnam Vet: 2016-17 dreams   \n",
       "27948  Vietnam Vet: 2016-17 dreams   \n",
       "27949  Vietnam Vet: 2016-17 dreams   \n",
       "27950  Vietnam Vet: 2016-17 dreams   \n",
       "27951  Vietnam Vet: 2016-17 dreams   \n",
       "\n",
       "                                                  report  \n",
       "27942  With a community of men and several women, I'm...  \n",
       "27943  A man bearing a likeness to Donald Trump calls...  \n",
       "27944  The sparse jungle offers little camouflage. Hi...  \n",
       "27945  On a desolate farm, in a dirt lot, a very dark...  \n",
       "27946  At night, in a foreign land, I go from one res...  \n",
       "27947  In a town like the town I lived in from 2001 t...  \n",
       "27948  At night, as people leave, I'm standing in a f...  \n",
       "27949  I'm in an airplane flying high over the earth,...  \n",
       "27950  As an adult, I'm living at home with brother a...  \n",
       "27951  I'm part of a bombing mission over India. As w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_token = dreambank[['name', 'report']]\n",
    "dream_token.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb6849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_token.to_csv('dream_token.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5370952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one at the Meads's house, where it's bigger inside than out; there's a European village just inside, with a cobblestone street and a Pied-Piper sort of man with curly hair, he can do things like juggle - I go up the back stairs [there aren't any in the real house] and then down the other side [since there's a second set, immediately] then down a short empty hallway that turns a corner, where I find a tiny room...a young woman with shoulder-length blonde hair in a pageboy is there, cooking at a stove that almost fills the room...she's nice to me. Now outside, I'm waiting for my aunt to pick me up - she arrives in a little round convertible and we go for a drive, not very far - we cross a little bridge over a creek, then double back and she drops me off at the house again. Inside (?) I sit with a couple of people, playing with a string of blue balloons.\n"
     ]
    }
   ],
   "source": [
    "print(dreambank['report'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e67a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa289ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517401\n"
     ]
    }
   ],
   "source": [
    "print(len(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af2c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37319af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to normalize the data\n",
    "\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'name' not in df.columns or 'report' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'prompt' and 'result' columns.\")\n",
    "\n",
    "    conversations = df.apply(lambda row: f\"User: {row['name']}\\nBot: {row['report']}\", axis=1)\n",
    "    return Dataset.from_dict({\"text\": conversations.tolist()})\n",
    "\n",
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cde4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (check this:)\n",
    "\n",
    "#https://huggingface.co/docs/trl/sft_trainer\n",
    "#https://huggingface.co/docs/datasets/loading\n",
    "#https://medium.com/@prashanth.ramanathan/fine-tuning-a-pre-trained-gpt-2-model-and-performing-inference-a-hands-on-guide-57c097a3b810\n",
    "\n",
    "def get_latest_checkpoint(output_dir):\n",
    "    # Look for checkpoint folders like \"checkpoint-500\", \"checkpoint-1000\", etc.\n",
    "    checkpoints = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    # Sort by number and return latest\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    return checkpoints[-1]\n",
    "    \n",
    "def train_model(csv_path, output_dir, model_name=\"openai-community/gpt2\", epochs=3):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    latest_checkpoint = get_latest_checkpoint(output_dir)\n",
    "    model = GPT2LMHeadModel.from_pretrained(latest_checkpoint if latest_checkpoint else model_name)\n",
    "\n",
    "    dataset = load_csv_dataset(csv_path)\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=2,\n",
    "        num_train_epochs=epochs,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        fp16=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=latest_checkpoint if latest_checkpoint else None)\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e686a2-abf7-411e-bc53-b95126abe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#csv_path = 'dream_token.csv'\n",
    "#output_dir = 'trained_model_v1'\n",
    "#train_model(csv_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee5c37-4b2d-4609-b387-3b609a8209d7",
   "metadata": {},
   "source": [
    "# De aqui en adelante emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5026c17-fd69-451d-8226-f98d8b8d5cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c644016e0b964a4aaec6de61045b5d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/517401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74157/780926547.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='776103' max='776103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [776103/776103 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'file' not in df.columns or 'message' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'prompt' and 'result' columns.\")\n",
    "\n",
    "    conversations = df.apply(lambda row: f\"User: {row['file']}\\nBot: {row['message']}\", axis=1)\n",
    "    return Dataset.from_dict({\"text\": conversations.tolist()})\n",
    "\n",
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "\n",
    "csv_path = 'emails_token.csv'\n",
    "output_dir = 'trained_model_v2'\n",
    "train_model(csv_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fc0f8-034a-4df7-ace5-a624156cfeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
