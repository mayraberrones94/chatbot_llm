{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ad0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb414a53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m generator = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpt2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m set_seed(\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ame/lib/python3.11/site-packages/transformers/pipelines/__init__.py:1020\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1015\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1016\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mYou cannot use both `pipeline(... torch_dtype=..., model_kwargs=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:...})` as those\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1017\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m arguments might conflict, use only one.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         )\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(torch_dtype, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m, torch_dtype):\n\u001b[32m   1021\u001b[39m         torch_dtype = \u001b[38;5;28mgetattr\u001b[39m(torch, torch_dtype)\n\u001b[32m   1022\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m] = torch_dtype\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2', torch_dtype=torch.float16)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c4b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, and my project is based on the idea of a language model.\\n\\nI want to have a language that's both expressive and readable.\\n\\nLet's look at the following code:\\n\\nimport Data.ByteString\\n\\ndef get ( self ):\\n\\nself.data = Data.ByteString(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data.get())\\n\\nself.data.append(data\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a language model, and if I don't understand it, I won't learn to write it. So I was writing a system for programming in JavaScript and a system for writing systems for programming in Python and a system for writing systems for programming in C++. And then I realized I was writing a language model, not a language model, because I was writing a language model for programming in JavaScript and a language model for writing systems for programming in Python and a language model for writing systems for programming in C++. And I realized that I needed something to write things that were a bit more complicated. And so I wrote a system for programming in JavaScript and a system for writing systems for programming in Python and a system for writing systems for programming in C++. And I realized that I needed something to write things that were a bit more complicated. And so I decided to give up on the language model. And so I decided to give up on the language model.\\n\\nAnd so I took a look at the documentation and realized something was wrong. I realized that the documentation was about building systems that were not a bit more complicated. And so I decided to give up on the language model. And so I took a look at the documentation and realized something was wrong. I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'm trying to learn some things. I'm trying to learn a lot of things without being able to understand what's going on.\\n\\nI think this is a common theme with people in the field and in the software industry. There are always people who want to talk about how the world is different, but at the same time they are still trying to learn things. The question is, can you create something that's really easy for people to understand and that's more fun, more accessible, in a way?\\n\\nJ: Yeah, but I think there's some things that we've been really good at. The thing that's really important is to make it accessible for everybody, and because we've been doing it for a while, so we've learned a lot. We've also learned a lot of other things. We've been really good at creating great things, and I think that's one of the things that is really important.\\n\\nM: What's your favorite project, and what's it been like to make it?\\n\\nJ: I'm very happy with it. It's a very difficult project. It's very hard. It's very hard to create something that is fun and accessible and interesting. I think we all like to\"},\n",
       " {'generated_text': \"Hello, I'm a language model, but I don't believe in a language model. I'm a language model. I don't like to think of myself as a model, but I do want to do better than I do right now. So I think that the future is not going to be built on a theory that I'm not familiar with. The future is being built on a theory that I'm not familiar with.\\n\\nI'm also a language model. I'm a language model. Even though I'm very vocal about the need for strong, cohesive, deep software, I think it's important to understand both the language model and the software model as well. I think the best way to think about it is by going back to a very early age where you can't see the human language. You can't see the computer language. You can't see the human brain. You can't see the computer brain. You can't see the human mind. You can't see the human mind.\\n\\nSo it's not like you can't see the human mind. It's like you can't see the human mind. It's like you can't see the human brain. It's like you can't see the human mind.\\n\\nSo it's not like you can't see the human\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, not an implementation.\\n\\nYou can imagine how it\\'s like to see a language model in action, using an interface.\\n\\nI\\'ll start with a simple example, which is a simple one.\\n\\nimport java.io.* ; class ExampleApp extends System.IO. Generic. System { static void main ( String [] args ) { System. out. println ( \"Hello, World!\" ); } }\\n\\nI\\'m not just talking about Java. I\\'m also talking about all the other languages I\\'ve learned in my life, which are so fascinating for me to see how they work.\\n\\nThat\\'s like saying I\\'ll learn all the languages in my life.\\n\\nLet\\'s have a look at some examples:\\n\\n< I\\'m using Java.io.Console, which is a Java.IO.Console class.>\\n\\nI\\'m using Java.IO.Console, which is a java.io.Console class. I\\'m using Java.IO.Console.class, which is a java.io.Console class. I\\'m using Java.IO.Console.class, which is a java.io.Console class. I\\'m using java.io.Console.class, which is a java.io.Console class.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d36d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>report</th>\n",
       "      <th>character</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1957</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>The one at the Meads's house, where it's bigge...</td>\n",
       "      <td>1MSA, 1FSA, 1FKA, 2ISA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>2</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/11/67</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm at a family reunion in a large fine house ...</td>\n",
       "      <td>2MSA, 2JSA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>3</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>8/1/85</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I watch a plane fly past and shortly realize i...</td>\n",
       "      <td>2ISA, 1FSA, 2ISA, 1MKA, 1MKA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>4</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>Me pulling the green leaves and berries off so...</td>\n",
       "      <td>1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>5</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>1985?</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>I'm in a room that reminds me of (but definite...</td>\n",
       "      <td>1MKA, 2IOA, 1MKA, 2JSA, 1MSA</td>\n",
       "      <td>CO D, AN 1MKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      name number       time     date gender age  \\\n",
       "0  alta  Alta: a detailed dreamer      1  1985-1997     1957      F   A   \n",
       "1  alta  Alta: a detailed dreamer      2  1985-1997  8/11/67      F   A   \n",
       "2  alta  Alta: a detailed dreamer      3  1985-1997   8/1/85      F   A   \n",
       "3  alta  Alta: a detailed dreamer      4  1985-1997    1985?      F   A   \n",
       "4  alta  Alta: a detailed dreamer      5  1985-1997    1985?      F   A   \n",
       "\n",
       "                                              report  \\\n",
       "0  The one at the Meads's house, where it's bigge...   \n",
       "1  I'm at a family reunion in a large fine house ...   \n",
       "2  I watch a plane fly past and shortly realize i...   \n",
       "3  Me pulling the green leaves and berries off so...   \n",
       "4  I'm in a room that reminds me of (but definite...   \n",
       "\n",
       "                            character        emotion  \n",
       "0              1MSA, 1FSA, 1FKA, 2ISA            NaN  \n",
       "1                          2MSA, 2JSA            NaN  \n",
       "2        2ISA, 1FSA, 2ISA, 1MKA, 1MKA            NaN  \n",
       "3  1MSC, 1FKA, 2JSA, 1ANI, 2MSA, 1ANI            NaN  \n",
       "4        1MKA, 2IOA, 1MKA, 2JSA, 1MSA  CO D, AN 1MKA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dreambank = pd.read_csv('dreambank.csv')\n",
    "dreambank.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628a392a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alta: a detailed dreamer', 'Angie: age 18 & 20',\n",
       "       'Arlie: a middle-aged woman', 'Barb Sanders', 'Barb Sanders #2',\n",
       "       'Bay Area girls: Grades 4-6', 'Bay Area girls: Grades 7-9',\n",
       "       'Bea 1: a high school student', 'Bea 2: a college student',\n",
       "       'Blind dreamers (F)', 'Blind dreamers (M)',\n",
       "       'Robert Bosnak: A dream analyst', 'Chris: a transvestite',\n",
       "       'Chuck: a physical scientist', 'College students, 1997-1998 (F)',\n",
       "       'College students, 1997-1998 (M)',\n",
       "       'Dahlia: concerns with appearance', 'David: teenage dreams',\n",
       "       'Dorothea: 53 years of dreams', 'Ed: dreams of his late wife',\n",
       "       'Edna: a blind woman', 'Elizabeth: a woman in her 40s',\n",
       "       'Emma: 48 years of dreams', \"Emma's Husband\",\n",
       "       'Esther: an adolescent girl', 'College women, late 1940s',\n",
       "       'Izzy (ALL, including non-consecutive)',\n",
       "       'Jasmine (ALL, including non-consecutive)',\n",
       "       'Jeff: a lucid dreamer', 'Joan: a lesbian', 'Kenneth',\n",
       "       'Lawrence, a young man', 'Madeline 1: High School',\n",
       "       'Madeline 2: College Dorms', 'Madeline 3: Off-Campus',\n",
       "       'Madeline 4: After College', 'Mack: A poor recaller',\n",
       "       'Mark: a young boy', 'Melissa: a young girl', 'Merri: an artist',\n",
       "       'Miami Home-Lab: Home', 'Miami Home-Lab: Lab',\n",
       "       \"Melora (Melvin's wife)\", \"Melvin (Melora's husband)\",\n",
       "       'Nancy: Caring & headstrong', 'The Natural Scientist',\n",
       "       'Norman: a child molester', 'Hall/VdC Norms: Female',\n",
       "       'Hall/VdC Norms: Male', 'Pegasus: a factory worker',\n",
       "       'Peruvian men', 'Peruvian women', 'Phil 1: teens',\n",
       "       'Phil 2: late 20s', 'Phil 3: retirement', 'The Physiologist',\n",
       "       'Pregnancy & Abortion', 'Ringo: from the 1960s',\n",
       "       'Sally: a forester', 'Samantha: in her 20s', 'Seventh grade girls',\n",
       "       'Midwest teenagers (F)', 'Midwest teenagers (M)',\n",
       "       'West Coast teenage girls', 'Toby: A friendly party animal',\n",
       "       'Tom: An outgoing man', 'UCSC women, 1996', 'Van: a video gamer',\n",
       "       'Vickie: a 10-year-old girl', 'Vietnam Vet: 1970-2008 war dreams',\n",
       "       'Vietnam Vet: 2015 dreams', 'Vietnam Vet: 2016-17 dreams'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dream = dreambank['name'].unique()\n",
    "name_dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c336e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dreambank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b7cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27942</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>With a community of men and several women, I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27943</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>A man bearing a likeness to Donald Trump calls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>The sparse jungle offers little camouflage. Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27945</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>On a desolate farm, in a dirt lot, a very dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27946</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, in a foreign land, I go from one res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27947</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>In a town like the town I lived in from 2001 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27948</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>At night, as people leave, I'm standing in a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27949</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm in an airplane flying high over the earth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27950</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>As an adult, I'm living at home with brother a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>Vietnam Vet: 2016-17 dreams</td>\n",
       "      <td>I'm part of a bombing mission over India. As w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "27942  Vietnam Vet: 2016-17 dreams   \n",
       "27943  Vietnam Vet: 2016-17 dreams   \n",
       "27944  Vietnam Vet: 2016-17 dreams   \n",
       "27945  Vietnam Vet: 2016-17 dreams   \n",
       "27946  Vietnam Vet: 2016-17 dreams   \n",
       "27947  Vietnam Vet: 2016-17 dreams   \n",
       "27948  Vietnam Vet: 2016-17 dreams   \n",
       "27949  Vietnam Vet: 2016-17 dreams   \n",
       "27950  Vietnam Vet: 2016-17 dreams   \n",
       "27951  Vietnam Vet: 2016-17 dreams   \n",
       "\n",
       "                                                  report  \n",
       "27942  With a community of men and several women, I'm...  \n",
       "27943  A man bearing a likeness to Donald Trump calls...  \n",
       "27944  The sparse jungle offers little camouflage. Hi...  \n",
       "27945  On a desolate farm, in a dirt lot, a very dark...  \n",
       "27946  At night, in a foreign land, I go from one res...  \n",
       "27947  In a town like the town I lived in from 2001 t...  \n",
       "27948  At night, as people leave, I'm standing in a f...  \n",
       "27949  I'm in an airplane flying high over the earth,...  \n",
       "27950  As an adult, I'm living at home with brother a...  \n",
       "27951  I'm part of a bombing mission over India. As w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_token = dreambank[['name', 'report']]\n",
    "dream_token.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dream_token.to_csv('dream_token.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5370952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one at the Meads's house, where it's bigger inside than out; there's a European village just inside, with a cobblestone street and a Pied-Piper sort of man with curly hair, he can do things like juggle - I go up the back stairs [there aren't any in the real house] and then down the other side [since there's a second set, immediately] then down a short empty hallway that turns a corner, where I find a tiny room...a young woman with shoulder-length blonde hair in a pageboy is there, cooking at a stove that almost fills the room...she's nice to me. Now outside, I'm waiting for my aunt to pick me up - she arrives in a little round convertible and we go for a drive, not very far - we cross a little bridge over a creek, then double back and she drops me off at the house again. Inside (?) I sit with a couple of people, playing with a string of blue balloons.\n"
     ]
    }
   ],
   "source": [
    "print(dreambank['report'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e67a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6aa289ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517401\n"
     ]
    }
   ],
   "source": [
    "print(len(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b0650b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9705d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <33076797.1075855687515.JavaMail.evans@thyme>\n",
      "Date: Mon, 16 Oct 2000 06:42:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: buck.buckner@honeywell.com\n",
      "Subject: Re: FW: fixed forward or other Collar floor gas price terms\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: \"Buckner, Buck\" <buck.buckner@honeywell.com> @ ENRON\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Mr. Buckner,\n",
      "\n",
      " For delivered gas behind San Diego, Enron Energy Services is the appropriate \n",
      "Enron entity.  I have forwarded your request to Zarin Imam at EES.  Her phone \n",
      "number is 713-853-7107.  \n",
      "\n",
      "Phillip Allen\n"
     ]
    }
   ],
   "source": [
    "print(emails['message'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "210553cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = emails['message'][100].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "257a1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X-FileName: pallen.nsf',\n",
       " '',\n",
       " \"I tried the new address but I don't have access.  also, what do I need to \",\n",
       " 'enter under domain?']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "363eb6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n6/yjb8n_px3wg30q8vy_hd6m6mmvt5d2/T/ipykernel_28200/3051276868.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  emails['file'][i] = lines_clean\n",
      "/var/folders/n6/yjb8n_px3wg30q8vy_hd6m6mmvt5d2/T/ipykernel_28200/3051276868.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  emails['message'][i] = report_clean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(emails)):\n",
    "    lines = emails['message'][i].split('\\n')\n",
    "    lines_clean = (\n",
    "        lines[4]\n",
    "        .replace('Subject:', '')\n",
    "        .replace('Re:', '')\n",
    "        .replace('FW:', '')\n",
    "    )\n",
    "    emails['file'][i] = lines_clean\n",
    "    rep = \" \".join(lines[14:])\n",
    "    report_clean = (\n",
    "        rep\n",
    "        .replace('X-FileName:', '')\n",
    "        .replace('pallen', '')\n",
    "        .replace('.nsf', '')\n",
    "        .replace('(Non-Privileged).pst', '')\n",
    "        .replace('-', '')\n",
    "    )\n",
    "    emails['message'][i] = report_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9c1c31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Here is our forecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Traveling to have a business meeting takes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Randy,   Can you send me a schedule of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file                                            message\n",
       "0                                     Here is our forecast   \n",
       "1               Traveling to have a business meeting takes...\n",
       "2     test                     test successful.  way to go!!!\n",
       "3              Randy,   Can you send me a schedule of the ...\n",
       "4    Hello                Let's shoot for Tuesday at 11:45.  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76dabd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.to_csv(\"emails_token.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af2c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mberronesreyes/anaconda3/envs/agnes_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37319af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to normalize the data\n",
    "\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'name' not in df.columns or 'report' not in df.columns:\n",
    "        raise ValueError(\"Change name columns\")\n",
    "\n",
    "    conversations = df.apply(lambda row: f\"User: {row['name']}\\nBot: {row['report']}\", axis=1)\n",
    "    return Dataset.from_dict({\"text\": conversations.tolist()})\n",
    "\n",
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cde4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (check this:)\n",
    "\n",
    "#https://huggingface.co/docs/trl/sft_trainer\n",
    "#https://huggingface.co/docs/datasets/loading\n",
    "#https://medium.com/@prashanth.ramanathan/fine-tuning-a-pre-trained-gpt-2-model-and-performing-inference-a-hands-on-guide-57c097a3b810\n",
    "\n",
    "def train_model(csv_path, output_dir, model_name=\"openai-community/gpt2\", epochs=3):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    dataset = load_csv_dataset(csv_path)\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=2,\n",
    "        num_train_epochs=epochs,\n",
    "        save_total_limit=1,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        fp16=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d18c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 27952/27952 [00:16<00:00, 1711.07 examples/s]\n",
      "/var/folders/n6/yjb8n_px3wg30q8vy_hd6m6mmvt5d2/T/ipykernel_65509/1899367562.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdream_token.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m         \u001b[38;5;66;03m# Path to your CSV\u001b[39;00m\n\u001b[1;32m      3\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m      \u001b[38;5;66;03m# Directory to save the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(csv_path, output_dir, model_name, epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     17\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m     18\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     38\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(output_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/agnes_llm/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agnes_llm/lib/python3.10/site-packages/transformers/trainer.py:471\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 471\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/anaconda3/envs/agnes_llm/lib/python3.10/site-packages/transformers/trainer.py:5176\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5173\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequires accelerate>1.3.0 to use Tensor Parallelism.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5175\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5177\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "File \u001b[0;32m~/anaconda3/envs/agnes_llm/lib/python3.10/site-packages/accelerate/accelerator.py:547\u001b[0m, in \u001b[0;36mAccelerator.__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdaa\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(check_is_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    548\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler\u001b[38;5;241m.\u001b[39mto_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# FSDP2 doesn't use ShardedGradScaler, don't want to modify `get_grad_scaler`, rather create a simple utility\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 6: Run the training\n",
    "csv_path = \"dream_token.csv\"         # Path to your CSV\n",
    "output_dir = \"trained_model_v1\"      # Directory to save the model\n",
    "train_model(csv_path, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
